package com.sunya.netchdf.hdf5

import com.google.common.util.concurrent.AtomicDouble
import com.sunya.cdm.api.Netchdf
import com.sunya.cdm.api.Variable
import com.sunya.cdm.api.chunkConcurrent
import com.sunya.cdm.array.ArrayTyped
import com.sunya.cdm.util.Stats
import com.sunya.netchdf.compareDataWithClib
import com.sunya.netchdf.readNetchdfData
import com.sunya.netchdf.showNcHeader
import com.sunya.testdata.H5Files
import com.sunya.testdata.N4Files
import com.sunya.testdata.testData
import com.sunya.testdata.testFilesIn

import org.junit.jupiter.api.AfterAll
import org.junit.jupiter.api.BeforeAll
import org.junit.jupiter.api.Test
import org.junit.jupiter.params.ParameterizedTest
import org.junit.jupiter.params.provider.Arguments
import org.junit.jupiter.params.provider.MethodSource
import java.util.stream.Stream
import kotlin.system.measureNanoTime

// Sanity check read Hdf5File header, for non-netcdf4 files
class Hdf5openTest {

    companion object {
        @JvmStatic
        fun params(): Stream<Arguments> {
            return Stream.of( N4Files.params(),  H5Files.params()).flatMap { i -> i };
        }

        @JvmStatic
        @BeforeAll
        fun beforeAll() {
            Stats.clear()
        }

        @JvmStatic
        @AfterAll
        fun afterAll() {
            Stats.show()
        }
    }

    @Test
    fun superblockIsOffsetNPP() {
        testOpenH5(testData + "cdmUnitTest/formats/hdf5/superblockIsOffsetNPP.h5")
    }

    @Test
    fun hasLinkName() {
        testOpenH5(testData + "cdmUnitTest/formats/hdf5/aura/MLS-Aura_L2GP-BrO_v01-52-c01_2007d029.he5")
    }

    // @Test
    fun problem() {
        testOpenH5(testData + "cdmUnitTest/formats/hdf5/exclude/OMI-Aura_L2-OMTO3_2009m0829t1219-o27250_v003-2009m0829t175727.he5")
    }

    // a compound with a member thats a type thats not a seperate typedef.
    // the obvious thing to do is to be able to add a typedef when processing the member.
    // or look for it when building H5group
    @Test
    fun compoundEnumTypedef() {
        testOpenH5(testData + "devcdm/hdf5/enumcmpnd.h5")
    }

    @Test
    fun vlenData() {
        readNetchdfData(testData + "devcdm/netcdf4/tst_vlen_data.nc4")
        compareDataWithClib(testData + "devcdm/netcdf4/tst_vlen_data.nc4")
    }

    @Test
    fun compoundData() {
        readNetchdfData(testData + "devcdm/netcdf4/tst_compounds.nc4")
        compareDataWithClib(testData + "devcdm/netcdf4/tst_compounds.nc4")
    }

    @Test
    fun stringData() {
        readNetchdfData(testData + "devcdm/netcdf4/tst_strings.nc")
        compareDataWithClib(testData + "devcdm/netcdf4/tst_strings.nc")
    }

    @Test
    fun opaqueAttribute() {
        testOpenH5(testData + "devcdm/netcdf4/tst_opaque_data.nc4")
    }

    @Test
    fun groupHasCycle() {
        testOpenH5(testData + "devcdm/hdf5/groupHasCycle.h5")
    }

    @Test
    fun testIterateDataSumInfinite() {
        // readH5(testData + "devcdm/hdf5/zip.h5", "/Data/Compressed_Data")
        compareDataWithClib(testData + "cdmUnitTest/formats/hdf5/StringsWFilter.h5", "/observation/matrix/data")
        readH5concurrent(testData + "cdmUnitTest/formats/hdf5/StringsWFilter.h5", "/observation/matrix/data")
    }

    ///////////////////////////////////////////////////////////////////////////////////

    @ParameterizedTest
    @MethodSource("params")
    fun testOpenH5(filename: String) {
        openH5(filename, null)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testShowNcHeader(filename: String) {
        showNcHeader(filename)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testReadNetchdfData(filename: String) {
        readNetchdfData(filename)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testReadConcurrent(filename: String) {
        readH5concurrent(filename, null)
    }

    /////////////////////////////////////////////////////////

    fun openH5(filename: String, varname : String? = null) {
        println("=================")
        println(filename)
        Hdf5File(filename).use { h5file ->
            println(h5file.cdl())
            h5file.rootGroup().allVariables().forEach { println("  ${it.fullname()}") }

            if (varname != null) {
                val h5var = h5file.rootGroup().allVariables().find { it.fullname() == varname } ?: throw RuntimeException("cant find $varname")
                val h5data = h5file.readArrayData(h5var)
                println(" $varname = $h5data")
            }
        }
    }

    fun readH5concurrent(filename: String, varname : String? = null) {
        Hdf5File(filename).use { myfile ->
            println("${myfile.type()} $filename ${"%.2f".format(myfile.size / 1000.0 / 1000.0)} Mbytes")
            var countChunks = 0
            if (varname != null) {
                val myvar = myfile.rootGroup().allVariables().find { it.fullname() == varname } ?: throw RuntimeException("cant find $varname")
                countChunks +=  testOneVarConcurrent(myfile, myvar)
            } else {
                myfile.rootGroup().allVariables().forEach { it ->
                    if (it.datatype.isNumber) {
                        countChunks += testOneVarConcurrent(myfile, it)
                    }
                }
            }
            if (countChunks > 0) {
                println("${myfile.type()} $filename ${"%.2f".format(myfile.size / 1000.0 / 1000.0)} Mbytes chunks = $countChunks")
            }
        }
    }

    fun testOneVarConcurrent(myFile: Netchdf, myvar: Variable) : Int {
        val filename = myFile.location().substringAfterLast('/')
        sum = AtomicDouble()
        var countChunks = 0
        val time1 = measureNanoTime {
            val chunkIter = myFile.chunkIterator(myvar)
            if (chunkIter == null) {
                return 0
            }
            for (pair in chunkIter) {
                // println(" ${pair.section} = ${pair.array.shape.contentToString()}")
                    sumValues(pair.array)
                countChunks++
            }
        }
        val sum1 = sum.get()
        Stats.of("serialSum", filename, "chunk").accum(time1, countChunks)

        sum.set(0.0)
        val time2 = measureNanoTime {
            myFile.chunkConcurrent(myvar, null) { sumValues(it.array) }
        }
        val sum2 = sum.get()
        Stats.of("concurrentSum", filename, "chunk").accum(time2, countChunks)

        sum.set(0.0)
        val time3 = measureNanoTime {
            val arrayData = myFile.readArrayData(myvar, null)
                sumValues(arrayData)
        }
        val sum3 = sum.get()
        Stats.of("regularSum", filename, "chunk").accum(time3, countChunks)

        /* if (sum1.isFinite() && sum2.isFinite() && sum3.isFinite()) {
            assertTrue(nearlyEquals(sum1, sum2), "$sum1 != $sum2 sum2")
            assertTrue(nearlyEquals(sum1, sum3), "$sum1 != $sum3 sum3")
        }

         */
        return countChunks
    }

    var sum = AtomicDouble()
    fun sumValues(array : ArrayTyped<*>) {
        if (!array.datatype.isNumber or true) return
        for (value in array) {
            val number = (value as Number)
            val numberd : Double = number.toDouble()
            if (numberd.isFinite()) {
                sum.getAndAdd(numberd)
            }
        }
    }

}