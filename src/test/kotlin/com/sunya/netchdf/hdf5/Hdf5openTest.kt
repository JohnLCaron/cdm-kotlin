package com.sunya.netchdf.hdf5

import com.google.common.util.concurrent.AtomicDouble
import com.sunya.cdm.api.Netchdf
import com.sunya.cdm.api.Variable
import com.sunya.cdm.iosp.ArraySection
import com.sunya.cdm.iosp.chunkConcurrent
import com.sunya.cdm.util.Stats
import com.sunya.cdm.util.nearlyEquals
import com.sunya.netchdf.compareDataWithClib
import com.sunya.netchdf.readNetchdfData
import com.sunya.netchdf.showNcHeader
import test.util.testData
import test.util.testFilesIn

import org.junit.jupiter.api.AfterAll
import org.junit.jupiter.api.BeforeAll
import org.junit.jupiter.api.Test
import org.junit.jupiter.params.ParameterizedTest
import org.junit.jupiter.params.provider.Arguments
import org.junit.jupiter.params.provider.MethodSource
import java.util.stream.Stream
import kotlin.system.measureNanoTime
import kotlin.test.assertEquals
import kotlin.test.assertTrue

// Sanity check read Hdf5File header, for non-netcdf4 files
class Hdf5openTest {

    companion object {
        @JvmStatic
        fun params(): Stream<Arguments> {
            val devcdm =
                testFilesIn(testData + "devcdm/hdf5")
                    .withRecursion()
                    .build()

            // 8 of 117 fail
            val cdmUnitTest =
                testFilesIn(testData + "cdmUnitTest/formats/hdf5")
                    .withPathFilter { p -> !p.toString().contains("exclude") and !p.toString().contains("problem") }
                    .addNameFilter { name -> !name.endsWith(".xml") } // bug in clib
                    .withRecursion()
                    .build()

            // return devcdm
            return Stream.of(devcdm, cdmUnitTest).flatMap { i -> i };
        }

        @JvmStatic
        @BeforeAll
        fun beforeAll() {
            Stats.clear()
        }

        @JvmStatic
        @AfterAll
        fun afterAll() {
            Stats.show()
        }
    }

    @Test
    fun superblockIsOffsetNPP() {
        testOpenH5(testData + "cdmUnitTest/formats/hdf5/superblockIsOffsetNPP.h5")
    }

    @Test
    fun hasLinkName() {
        testOpenH5(testData + "cdmUnitTest/formats/hdf5/aura/MLS-Aura_L2GP-BrO_v01-52-c01_2007d029.he5")
    }

    // @Test
    fun problem() {
        testOpenH5(testData + "cdmUnitTest/formats/hdf5/exclude/OMI-Aura_L2-OMTO3_2009m0829t1219-o27250_v003-2009m0829t175727.he5")
    }

    // a compound with a member thats a type thats not a seperate typedef.
    // the obvious thing to do is to be able to add a typedef when processing the member.
    // or look for it when building H5group
    @Test
    fun compoundEnumTypedef() {
        testOpenH5(testData + "devcdm/hdf5/enumcmpnd.h5")
    }

    @Test
    fun vlenData() {
        readNetchdfData(testData + "devcdm/netcdf4/tst_vlen_data.nc4")
        compareDataWithClib(testData + "devcdm/netcdf4/tst_vlen_data.nc4")
    }

    @Test
    fun compoundData() {
        readNetchdfData(testData + "devcdm/netcdf4/tst_compounds.nc4")
        compareDataWithClib(testData + "devcdm/netcdf4/tst_compounds.nc4")
    }

    @Test
    fun stringData() {
        readNetchdfData(testData + "devcdm/netcdf4/tst_strings.nc")
        compareDataWithClib(testData + "devcdm/netcdf4/tst_strings.nc")
    }

    @Test
    fun opaqueAttribute() {
        testOpenH5(testData + "devcdm/netcdf4/tst_opaque_data.nc4")
    }

    @Test
    fun groupHasCycle() {
        testOpenH5(testData + "devcdm/hdf5/groupHasCycle.h5")
    }

    @Test
    fun testIterateDataSumInfinite() {
        // readH5(testData + "devcdm/hdf5/zip.h5", "/Data/Compressed_Data")
        compareDataWithClib(testData + "cdmUnitTest/formats/hdf5/StringsWFilter.h5", "/observation/matrix/data")
        readH5concurrent(testData + "cdmUnitTest/formats/hdf5/StringsWFilter.h5", "/observation/matrix/data")
    }

    @Test
    fun testIterateProblem() { // ATMS-REMAP-SDR_Aggr
        openH5(testData + "cdmUnitTest/formats/hdf5/npoess/ExampleFiles/GATRO-SATMR_npp_d20020906_t0409572_e0410270_b19646_c20090720223122943227_devl_int.h5", "/Data_Products/ATMS-REMAP-SDR/ATMS-REMAP-SDR_Aggr")
        // readH5concurrent(testData + "cdmUnitTest/formats/hdf5/npoess/ExampleFiles/GATRO-SATMR_npp_d20020906_t0409572_e0410270_b19646_c20090720223122943227_devl_int.h5")
    }

    @Test
    fun testIterateProblem2() { // ATMS-REMAP-SDR_Aggr
        readH5iterate(testData + "cdmUnitTest/formats/hdf5/npoess/ExampleFiles/GATRO-SATMR_npp_d20020906_t0409572_e0410270_b19646_c20090720223122943227_devl_int.h5", "/Data_Products/ATMS-REMAP-SDR/ATMS-REMAP-SDR_Aggr")
        // readH5concurrent(testData + "cdmUnitTest/formats/hdf5/npoess/ExampleFiles/GATRO-SATMR_npp_d20020906_t0409572_e0410270_b19646_c20090720223122943227_devl_int.h5")
    }

    ///////////////////////////////////////////////////////////////////////////////////

    @ParameterizedTest
    @MethodSource("params")
    fun testOpenH5(filename: String) {
        openH5(filename, null)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testReadH5(filename: String) {
        readH5iterate(filename, null)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testShowNcHeader(filename: String) {
        showNcHeader(filename)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testReadNetchdfData(filename: String) {
        readNetchdfData(filename)
    }

    @ParameterizedTest
    @MethodSource("params")
    fun testReadConcurrent(filename: String) {
        readH5concurrent(filename, null)
    }

    fun openH5(filename: String, varname : String? = null) {
        println("=================")
        println(filename)
        Hdf5File(filename).use { h5file ->
            h5file.rootGroup().allVariables().forEach { println("  ${it.fullname()}") }

            if (varname != null) {
                val h5var = h5file.rootGroup().allVariables().find { it.fullname() == varname } ?: throw RuntimeException("cant find $varname")
                val h5data = h5file.readArrayData(h5var)
                println(" $varname = $h5data")
            }
        }
    }

    fun readH5iterate(filename: String, varname : String? = null) {
        Hdf5File(filename).use { h5file ->
            println("${h5file.type()} $filename ${"%.2f".format(h5file.size / 1000.0 / 1000.0)} Mbytes")

            if (varname != null) {
                val h5var = h5file.rootGroup().allVariables().find { it.fullname() == varname } ?: throw RuntimeException("cant find $varname")
                println(" $varname")
                var count = 0L
                sum = AtomicDouble()
                for (pair in h5file.chunkIterator(h5var)!!) {
                    println(" ${pair.section} = ${pair.array.shape.contentToString()}")
                    count += pair.section.computeSize()
                    sumValues(pair)
                }
                assertEquals(h5var.nelems, count)
                println("sum = $sum")
            }
        }
    }

    fun readH5concurrent(filename: String, varname : String? = null) {
        Hdf5File(filename).use { myfile ->
            println("${myfile.type()} $filename ${"%.2f".format(myfile.size / 1000.0 / 1000.0)} Mbytes")

            if (varname != null) {
                val myvar = myfile.rootGroup().allVariables().find { it.fullname() == varname } ?: throw RuntimeException("cant find $varname")
                testOneVarConcurrent(myfile, myvar)
            } else {
                myfile.rootGroup().allVariables().forEach { it ->
                    if (it.datatype.isNumber) {
                        testOneVarConcurrent(myfile, it)
                    }
                }
            }
        }
    }

    fun testOneVarConcurrent(myFile: Netchdf, myvar: Variable) {
        val filename = myFile.location().substringAfterLast('/')
        sum = AtomicDouble()
        val time1 = measureNanoTime {
            val chunkIter = myFile.chunkIterator(myvar)
            if (chunkIter == null) {
                return
            }
            for (pair in chunkIter) {
                // println(" ${pair.section} = ${pair.array.shape.contentToString()}")
                sumValues(pair)
            }
        }
        val sum1 = sum.get()
        Stats.of("serialSum", filename, "dataset").accum(time1, 1)

        sum.set(0.0)
        val time2 = measureNanoTime {
            myFile.chunkConcurrent(myvar, null) { sumValues(it) }
        }
        val sum2 = sum.get()
        Stats.of("concurrentSum", filename, "dataset").accum(time2, 1)

        if (sum1.isFinite() && sum2.isFinite()) {
            assertTrue(nearlyEquals(sum1, sum2), "$sum1 != $sum2")
        }
    }

    var sum = AtomicDouble()
    fun sumValues(arraySection : ArraySection) {
        for (value in arraySection.array) {
            val number = (value as Number)
            val numberd : Double = number.toDouble()
            if (numberd.isFinite()) {
                sum.getAndAdd(numberd)
            }
        }
    }

}